{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dynamic Pricing / Discount Optimization Model\n",
        "\n",
        "## Farm2Home ML Model Training\n",
        "\n",
        "This notebook trains a machine learning model to predict optimal discounts (0-30%) for products that maximize revenue while maintaining conversion rates.\n",
        "\n",
        "**Features:**\n",
        "- Product base price\n",
        "- Category\n",
        "- Past sales volume\n",
        "- Discount percentage\n",
        "- Seasonal features (month, day of week)\n",
        "- Price elasticity estimation\n",
        "\n",
        "**Output:** \n",
        "- `dynamic_pricing_model.pkl` - Trained model\n",
        "- `input_scaler.pkl` - Feature scaler\n",
        "- `product_encoder.pkl` - Category encoder\n",
        "\n",
        "**Goal:** Suggest optimal discount % (0-30%) that maximizes revenue per product.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import xgboost as xgb\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Order History Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“š Loading order history dataset...\n",
            "âš ï¸  Could not load CSV files: [Errno 2] No such file or directory: 'order_history.csv'\n",
            "ğŸ“Š Generating synthetic order history data for training...\n",
            "âœ… Generated 5000 synthetic records\n",
            "ğŸ“Š Records with purchases: 3138\n",
            "ğŸ“Š Unique products: 791\n",
            "ğŸ“Š Categories: 8\n",
            "\n",
            "ğŸ“‹ Dataset Info:\n",
            "       product_id      product_name  base_price  offered_discount  \\\n",
            "0     PROD_Oil_52     Oil Product 1      387.68             21.96   \n",
            "1    PROD_Nuts_24    Nuts Product 1      590.53              1.69   \n",
            "2  PROD_Pulses_89  Pulses Product 1      107.86             18.36   \n",
            "3     PROD_Oil_64     Oil Product 2      266.69             25.80   \n",
            "4   PROD_Fruits_9  Fruits Product 1       83.51              6.93   \n",
            "\n",
            "   quantity_ordered  conversion_rate  purchased category  past_sales_volume  \\\n",
            "0                 9           0.5939          1      Oil                  9   \n",
            "1                 0           0.3055          0     Nuts                  0   \n",
            "2                 0           0.4613          0   Pulses                  0   \n",
            "3                 0           0.4138          0      Oil                  0   \n",
            "4                 7           0.6845          1   Fruits                  7   \n",
            "\n",
            "                  order_date  month  day_of_week  is_weekend  \n",
            "0 2025-07-28 09:36:03.068690      7            0           0  \n",
            "1 2024-12-26 09:36:03.068956     12            3           0  \n",
            "2 2024-11-06 09:36:03.069128     11            2           0  \n",
            "3 2025-03-08 09:36:03.069282      3            5           1  \n",
            "4 2025-08-16 09:36:03.069482      8            5           1  \n",
            "\n",
            "ğŸ“Š Dataset shape: (5000, 13)\n",
            "ğŸ“Š Missing values:\n",
            "product_id           0\n",
            "product_name         0\n",
            "base_price           0\n",
            "offered_discount     0\n",
            "quantity_ordered     0\n",
            "conversion_rate      0\n",
            "purchased            0\n",
            "category             0\n",
            "past_sales_volume    0\n",
            "order_date           0\n",
            "month                0\n",
            "day_of_week          0\n",
            "is_weekend           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load data from CSV files or generate synthetic data\n",
        "print(\"ğŸ“š Loading order history dataset...\")\n",
        "\n",
        "try:\n",
        "    # Try loading from CSV files\n",
        "    order_history_df = pd.read_csv('../order_history.csv')\n",
        "    print(\"âœ… Loaded from CSV file\")\n",
        "except:\n",
        "    try:\n",
        "        order_history_df = pd.read_csv('order_history.csv')\n",
        "        print(\"âœ… Loaded from current directory\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  Could not load CSV files: {e}\")\n",
        "        print(\"ğŸ“Š Generating synthetic order history data for training...\")\n",
        "        \n",
        "        # Generate comprehensive synthetic data\n",
        "        np.random.seed(42)\n",
        "        n_records = 5000\n",
        "        \n",
        "        # Product categories\n",
        "        categories = ['Vegetables', 'Fruits', 'Grains', 'Dairy', 'Spices', 'Pulses', 'Oil', 'Nuts']\n",
        "        \n",
        "        # Product base prices (varies by category)\n",
        "        category_base_prices = {\n",
        "            'Vegetables': (50, 200),\n",
        "            'Fruits': (80, 300),\n",
        "            'Grains': (40, 150),\n",
        "            'Dairy': (60, 250),\n",
        "            'Spices': (100, 500),\n",
        "            'Pulses': (70, 200),\n",
        "            'Oil': (150, 400),\n",
        "            'Nuts': (200, 800)\n",
        "        }\n",
        "        \n",
        "        # Generate synthetic data\n",
        "        data = []\n",
        "        products = {}\n",
        "        \n",
        "        for i in range(n_records):\n",
        "            category = np.random.choice(categories)\n",
        "            product_id = f\"PROD_{category}_{np.random.randint(1, 100)}\"\n",
        "            \n",
        "            # Base price based on category\n",
        "            min_price, max_price = category_base_prices[category]\n",
        "            base_price = np.random.uniform(min_price, max_price)\n",
        "            \n",
        "            # Discount percentage (0-30%)\n",
        "            offered_discount = np.random.uniform(0, 30)\n",
        "            \n",
        "            # Discount affects quantity ordered (price elasticity)\n",
        "            # Higher discount = more quantity, but with diminishing returns\n",
        "            elasticity_factor = 1 + (offered_discount / 100) * np.random.uniform(0.5, 2.0)\n",
        "            base_quantity = np.random.randint(1, 20)\n",
        "            quantity_ordered = max(1, int(base_quantity * elasticity_factor))\n",
        "            \n",
        "            # Conversion rate (higher discount = higher conversion, but not linear)\n",
        "            base_conversion = np.random.uniform(0.3, 0.9)\n",
        "            conversion_boost = (offered_discount / 100) * np.random.uniform(0.1, 0.3)\n",
        "            conversion_rate = min(1.0, base_conversion + conversion_boost)\n",
        "            \n",
        "            # Purchase decision (binary)\n",
        "            purchased = 1 if np.random.random() < conversion_rate else 0\n",
        "            \n",
        "            # Past sales volume (cumulative)\n",
        "            if product_id not in products:\n",
        "                products[product_id] = {\n",
        "                    'past_sales_volume': 0,\n",
        "                    'product_name': f\"{category} Product {len([p for p in products.keys() if category in p]) + 1}\"\n",
        "                }\n",
        "            \n",
        "            # Date feature (seasonality)\n",
        "            days_ago = np.random.randint(0, 365)\n",
        "            order_date = datetime.now() - timedelta(days=days_ago)\n",
        "            \n",
        "            # Update past sales volume\n",
        "            if purchased:\n",
        "                products[product_id]['past_sales_volume'] += quantity_ordered\n",
        "            \n",
        "            data.append({\n",
        "                'product_id': product_id,\n",
        "                'product_name': products[product_id]['product_name'],\n",
        "                'base_price': round(base_price, 2),\n",
        "                'offered_discount': round(offered_discount, 2),\n",
        "                'quantity_ordered': quantity_ordered if purchased else 0,\n",
        "                'conversion_rate': round(conversion_rate, 4),\n",
        "                'purchased': purchased,\n",
        "                'category': category,\n",
        "                'past_sales_volume': products[product_id]['past_sales_volume'],\n",
        "                'order_date': order_date,\n",
        "                'month': order_date.month,\n",
        "                'day_of_week': order_date.weekday(),\n",
        "                'is_weekend': 1 if order_date.weekday() >= 5 else 0\n",
        "            })\n",
        "        \n",
        "        order_history_df = pd.DataFrame(data)\n",
        "        print(f\"âœ… Generated {len(order_history_df)} synthetic records\")\n",
        "        print(f\"ğŸ“Š Records with purchases: {order_history_df['purchased'].sum()}\")\n",
        "        print(f\"ğŸ“Š Unique products: {order_history_df['product_id'].nunique()}\")\n",
        "        print(f\"ğŸ“Š Categories: {order_history_df['category'].nunique()}\")\n",
        "\n",
        "print(\"\\nğŸ“‹ Dataset Info:\")\n",
        "print(order_history_df.head())\n",
        "print(f\"\\nğŸ“Š Dataset shape: {order_history_df.shape}\")\n",
        "print(f\"ğŸ“Š Missing values:\\n{order_history_df.isnull().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Engineering features...\n",
            "âœ… Feature engineering completed\n",
            "\n",
            "ğŸ“‹ Engineered features:\n",
            "   discounted_price      revenue  price_elasticity_estimate  total_profit\n",
            "0        302.545472  2722.909248                   4.307566    280.525248\n",
            "1        580.550043     0.000000                   0.000000      0.000000\n",
            "2         88.056904     0.000000                   0.000000      0.000000\n",
            "3        197.883980     0.000000                   0.000000      0.000000\n",
            "4         77.722757   544.059299                   5.000000    134.860299\n",
            "\n",
            "ğŸ“Š Revenue statistics:\n",
            "count     3138.000000\n",
            "mean      2152.531580\n",
            "std       2054.861572\n",
            "min         30.926200\n",
            "25%        744.254406\n",
            "50%       1523.556702\n",
            "75%       2785.461738\n",
            "max      13871.198616\n",
            "Name: revenue, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"ğŸ”§ Engineering features...\")\n",
        "\n",
        "# Create a copy for feature engineering\n",
        "df = order_history_df.copy()\n",
        "\n",
        "# 1. Discounted price\n",
        "df['discounted_price'] = df['base_price'] * (1 - df['offered_discount'] / 100)\n",
        "\n",
        "# 2. Revenue (only for purchased items)\n",
        "df['revenue'] = df['discounted_price'] * df['quantity_ordered'] * df['purchased']\n",
        "\n",
        "# 3. Price elasticity estimate\n",
        "# Price elasticity = % change in quantity / % change in price\n",
        "# Higher discount should increase quantity, but effect diminishes\n",
        "df['price_change_pct'] = df['offered_discount'] / 100\n",
        "df['quantity_change_pct'] = np.where(\n",
        "    df['purchased'] == 1,\n",
        "    (df['quantity_ordered'] - df.groupby('product_id')['quantity_ordered'].transform('mean')) / \n",
        "    (df.groupby('product_id')['quantity_ordered'].transform('mean') + 1e-6),\n",
        "    0\n",
        ")\n",
        "\n",
        "# Simplified elasticity estimate\n",
        "df['price_elasticity_estimate'] = np.where(\n",
        "    df['price_change_pct'] > 0,\n",
        "    df['quantity_change_pct'] / (df['price_change_pct'] + 1e-6),\n",
        "    -1.0  # Default for no discount\n",
        ")\n",
        "\n",
        "# Clip extreme values\n",
        "df['price_elasticity_estimate'] = df['price_elasticity_estimate'].clip(-5, 5)\n",
        "\n",
        "# 4. Discount category (bins)\n",
        "df['discount_category'] = pd.cut(\n",
        "    df['offered_discount'],\n",
        "    bins=[-1, 5, 10, 15, 20, 25, 30],\n",
        "    labels=['0-5%', '5-10%', '10-15%', '15-20%', '20-25%', '25-30%']\n",
        ")\n",
        "\n",
        "# 5. Revenue per unit\n",
        "df['revenue_per_unit'] = df['revenue'] / (df['quantity_ordered'] + 1e-6)\n",
        "\n",
        "# 6. Profit margin estimate (assuming 30% margin on base price)\n",
        "df['cost_per_unit'] = df['base_price'] * 0.7\n",
        "df['profit_per_unit'] = df['discounted_price'] - df['cost_per_unit']\n",
        "df['total_profit'] = df['profit_per_unit'] * df['quantity_ordered'] * df['purchased']\n",
        "\n",
        "# 7. Seasonal features (already extracted in data generation)\n",
        "# month, day_of_week, is_weekend\n",
        "\n",
        "# 8. Category encoding (will be done later)\n",
        "# category\n",
        "\n",
        "# 9. Past performance features\n",
        "df['avg_past_sales'] = df.groupby('product_id')['past_sales_volume'].transform('mean')\n",
        "df['sales_volume_percentile'] = df.groupby('category')['past_sales_volume'].transform(\n",
        "    lambda x: pd.qcut(x, q=4, labels=False, duplicates='drop')\n",
        ").fillna(0)\n",
        "\n",
        "print(\"âœ… Feature engineering completed\")\n",
        "print(f\"\\nğŸ“‹ Engineered features:\\n{df[['discounted_price', 'revenue', 'price_elasticity_estimate', 'total_profit']].head()}\")\n",
        "print(f\"\\nğŸ“Š Revenue statistics:\")\n",
        "print(df[df['purchased'] == 1]['revenue'].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Training data shape: (3138, 25)\n",
            "ğŸ“Š Target variable stats:\n",
            "count     3138.000000\n",
            "mean      2152.531580\n",
            "std       2054.861572\n",
            "min         30.926200\n",
            "25%        744.254406\n",
            "50%       1523.556702\n",
            "75%       2785.461738\n",
            "max      13871.198616\n",
            "Name: revenue, dtype: float64\n",
            "\n",
            "âœ… Features prepared:\n",
            "   Feature shape: (3138, 9)\n",
            "   Target shape: (3138,)\n",
            "\n",
            "ğŸ“‹ Feature columns: ['base_price', 'offered_discount', 'category_encoded', 'past_sales_volume', 'price_elasticity_estimate', 'month', 'day_of_week', 'is_weekend', 'sales_volume_percentile']\n",
            "\n",
            "ğŸ“Š Feature statistics:\n",
            "        base_price  offered_discount  category_encoded  past_sales_volume  \\\n",
            "count  3138.000000       3138.000000       3138.000000        3138.000000   \n",
            "mean    221.325319         14.843811          3.497769          33.873805   \n",
            "std     150.448485          8.601924          2.305244          22.572054   \n",
            "min      40.400000          0.000000          0.000000           1.000000   \n",
            "25%     116.265000          7.370000          1.000000          17.000000   \n",
            "50%     175.605000         14.825000          4.000000          30.000000   \n",
            "75%     280.395000         22.237500          6.000000          47.750000   \n",
            "max     798.450000         29.990000          7.000000         120.000000   \n",
            "\n",
            "       price_elasticity_estimate        month  day_of_week   is_weekend  \\\n",
            "count                3138.000000  3138.000000  3138.000000  3138.000000   \n",
            "mean                    1.663534     6.518483     3.029637     0.285851   \n",
            "std                     3.686015     3.435986     1.992034     0.451891   \n",
            "min                    -5.000000     1.000000     0.000000     0.000000   \n",
            "25%                    -1.233077     3.250000     1.000000     0.000000   \n",
            "50%                     3.165709     7.000000     3.000000     0.000000   \n",
            "75%                     5.000000    10.000000     5.000000     1.000000   \n",
            "max                     5.000000    12.000000     6.000000     1.000000   \n",
            "\n",
            "       sales_volume_percentile  \n",
            "count              3138.000000  \n",
            "mean                  1.676864  \n",
            "std                   1.067433  \n",
            "min                   0.000000  \n",
            "25%                   1.000000  \n",
            "50%                   2.000000  \n",
            "75%                   3.000000  \n",
            "max                   3.000000  \n"
          ]
        }
      ],
      "source": [
        "# Select features for training\n",
        "# We want to predict revenue, so we'll use features that don't include revenue itself\n",
        "feature_columns = [\n",
        "    'base_price',\n",
        "    'offered_discount',\n",
        "    'category',\n",
        "    'past_sales_volume',\n",
        "    'price_elasticity_estimate',\n",
        "    'month',\n",
        "    'day_of_week',\n",
        "    'is_weekend',\n",
        "    'sales_volume_percentile'\n",
        "]\n",
        "\n",
        "# Target variable: revenue (what we want to maximize)\n",
        "target_column = 'revenue'\n",
        "\n",
        "# Filter to purchased items only (positive revenue)\n",
        "df_train = df[df['purchased'] == 1].copy()\n",
        "\n",
        "print(f\"ğŸ“Š Training data shape: {df_train.shape}\")\n",
        "print(f\"ğŸ“Š Target variable stats:\\n{df_train[target_column].describe()}\")\n",
        "\n",
        "# Encode categorical features\n",
        "category_encoder = LabelEncoder()\n",
        "df_train['category_encoded'] = category_encoder.fit_transform(df_train['category'])\n",
        "\n",
        "# Update feature columns to use encoded category\n",
        "feature_columns_encoded = [\n",
        "    'base_price',\n",
        "    'offered_discount',\n",
        "    'category_encoded',\n",
        "    'past_sales_volume',\n",
        "    'price_elasticity_estimate',\n",
        "    'month',\n",
        "    'day_of_week',\n",
        "    'is_weekend',\n",
        "    'sales_volume_percentile'\n",
        "]\n",
        "\n",
        "# Prepare X and y\n",
        "X = df_train[feature_columns_encoded].copy()\n",
        "y = df_train[target_column].copy()\n",
        "\n",
        "print(f\"\\nâœ… Features prepared:\")\n",
        "print(f\"   Feature shape: {X.shape}\")\n",
        "print(f\"   Target shape: {y.shape}\")\n",
        "print(f\"\\nğŸ“‹ Feature columns: {feature_columns_encoded}\")\n",
        "print(f\"\\nğŸ“Š Feature statistics:\")\n",
        "print(X.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Split Dataset (80/20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Dataset split:\n",
            "   Training set: 2510 samples\n",
            "   Test set: 628 samples\n",
            "   Split ratio: 80.0%\n"
          ]
        }
      ],
      "source": [
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"âœ… Dataset split:\")\n",
        "print(f\"   Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"   Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"   Split ratio: {X_train.shape[0] / (X_train.shape[0] + X_test.shape[0]):.1%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Scale Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Features scaled successfully\n",
            "   Scaled training shape: (2510, 9)\n",
            "   Scaled test shape: (628, 9)\n"
          ]
        }
      ],
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"âœ… Features scaled successfully\")\n",
        "print(f\"   Scaled training shape: {X_train_scaled.shape}\")\n",
        "print(f\"   Scaled test shape: {X_test_scaled.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train Multiple Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤– Training multiple regression models...\n",
            "\n",
            "1ï¸âƒ£ Training RandomForestRegressor...\n",
            "   âœ… RÂ² Score: 0.8570\n",
            "   âœ… RMSE: 777.4238\n",
            "   âœ… MAE: 486.7777\n",
            "\n",
            "2ï¸âƒ£ Training XGBoostRegressor...\n",
            "   âœ… RÂ² Score: 0.8431\n",
            "   âœ… RMSE: 814.4095\n",
            "   âœ… MAE: 489.8282\n",
            "\n",
            "3ï¸âƒ£ Training LinearRegression...\n",
            "   âœ… RÂ² Score: 0.7240\n",
            "   âœ… RMSE: 1079.9885\n",
            "   âœ… MAE: 763.3328\n",
            "\n",
            "âœ… All models trained successfully!\n"
          ]
        }
      ],
      "source": [
        "print(\"ğŸ¤– Training multiple regression models...\\n\")\n",
        "\n",
        "models = {}\n",
        "results = {}\n",
        "\n",
        "# 1. Random Forest Regressor\n",
        "print(\"1ï¸âƒ£ Training RandomForestRegressor...\")\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=15,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "models['RandomForest'] = rf_model\n",
        "\n",
        "rf_pred = rf_model.predict(X_test_scaled)\n",
        "rf_r2 = r2_score(y_test, rf_pred)\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
        "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
        "\n",
        "results['RandomForest'] = {\n",
        "    'r2': rf_r2,\n",
        "    'rmse': rf_rmse,\n",
        "    'mae': rf_mae\n",
        "}\n",
        "\n",
        "print(f\"   âœ… RÂ² Score: {rf_r2:.4f}\")\n",
        "print(f\"   âœ… RMSE: {rf_rmse:.4f}\")\n",
        "print(f\"   âœ… MAE: {rf_mae:.4f}\\n\")\n",
        "\n",
        "# 2. XGBoost Regressor\n",
        "print(\"2ï¸âƒ£ Training XGBoostRegressor...\")\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "models['XGBoost'] = xgb_model\n",
        "\n",
        "xgb_pred = xgb_model.predict(X_test_scaled)\n",
        "xgb_r2 = r2_score(y_test, xgb_pred)\n",
        "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
        "xgb_mae = mean_absolute_error(y_test, xgb_pred)\n",
        "\n",
        "results['XGBoost'] = {\n",
        "    'r2': xgb_r2,\n",
        "    'rmse': xgb_rmse,\n",
        "    'mae': xgb_mae\n",
        "}\n",
        "\n",
        "print(f\"   âœ… RÂ² Score: {xgb_r2:.4f}\")\n",
        "print(f\"   âœ… RMSE: {xgb_rmse:.4f}\")\n",
        "print(f\"   âœ… MAE: {xgb_mae:.4f}\\n\")\n",
        "\n",
        "# 3. Linear Regression\n",
        "print(\"3ï¸âƒ£ Training LinearRegression...\")\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "models['LinearRegression'] = lr_model\n",
        "\n",
        "lr_pred = lr_model.predict(X_test_scaled)\n",
        "lr_r2 = r2_score(y_test, lr_pred)\n",
        "lr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))\n",
        "lr_mae = mean_absolute_error(y_test, lr_pred)\n",
        "\n",
        "results['LinearRegression'] = {\n",
        "    'r2': lr_r2,\n",
        "    'rmse': lr_rmse,\n",
        "    'mae': lr_mae\n",
        "}\n",
        "\n",
        "print(f\"   âœ… RÂ² Score: {lr_r2:.4f}\")\n",
        "print(f\"   âœ… RMSE: {lr_rmse:.4f}\")\n",
        "print(f\"   âœ… MAE: {lr_mae:.4f}\\n\")\n",
        "\n",
        "print(\"âœ… All models trained successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Model Comparison:\n",
            "============================================================\n",
            "                        r2         rmse         mae\n",
            "RandomForest      0.857006   777.423808  486.777732\n",
            "XGBoost           0.843077   814.409471  489.828220\n",
            "LinearRegression  0.724044  1079.988481  763.332846\n",
            "============================================================\n",
            "\n",
            "ğŸ† Best Model: RandomForest\n",
            "   RÂ² Score: 0.8570\n",
            "   RMSE: 777.4238\n",
            "   MAE: 486.7777\n"
          ]
        }
      ],
      "source": [
        "# Compare models\n",
        "comparison_df = pd.DataFrame(results).T\n",
        "comparison_df = comparison_df.sort_values('r2', ascending=False)\n",
        "\n",
        "print(\"ğŸ“Š Model Comparison:\")\n",
        "print(\"=\" * 60)\n",
        "print(comparison_df.to_string())\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Select best model based on RÂ² and RMSE\n",
        "# Higher RÂ² and lower RMSE is better\n",
        "comparison_df['score'] = comparison_df['r2'] - (comparison_df['rmse'] / comparison_df['rmse'].max())\n",
        "best_model_name = comparison_df.sort_values('score', ascending=False).index[0]\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "print(f\"\\nğŸ† Best Model: {best_model_name}\")\n",
        "print(f\"   RÂ² Score: {results[best_model_name]['r2']:.4f}\")\n",
        "print(f\"   RMSE: {results[best_model_name]['rmse']:.4f}\")\n",
        "print(f\"   MAE: {results[best_model_name]['mae']:.4f}\")\n",
        "\n",
        "# Store for later use\n",
        "selected_model = best_model\n",
        "selected_model_name = best_model_name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Optimal discount prediction function created (improved with elasticity patterns)\n"
          ]
        }
      ],
      "source": [
        "def predict_optimal_discount(product_id, base_price, category, past_sales_volume, \n",
        "                             model, scaler, category_encoder, training_df=None,\n",
        "                             month=None, day_of_week=None, is_weekend=None):\n",
        "    \"\"\"\n",
        "    Predict optimal discount (0-30%) for a product that maximizes revenue.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    product_id : str\n",
        "        Product identifier\n",
        "    base_price : float\n",
        "        Base price of the product\n",
        "    category : str\n",
        "        Product category\n",
        "    past_sales_volume : float\n",
        "        Historical sales volume for the product\n",
        "    model : sklearn model\n",
        "        Trained regression model\n",
        "    scaler : sklearn scaler\n",
        "        Fitted StandardScaler\n",
        "    category_encoder : sklearn LabelEncoder\n",
        "        Fitted LabelEncoder for categories\n",
        "    training_df : pd.DataFrame, optional\n",
        "        Training dataframe to calculate elasticity patterns\n",
        "    month : int, optional\n",
        "        Month (1-12), defaults to current month\n",
        "    day_of_week : int, optional\n",
        "        Day of week (0-6), defaults to current day\n",
        "    is_weekend : int, optional\n",
        "        1 if weekend, 0 otherwise, defaults to current day\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : {\n",
        "        \"product\": str,\n",
        "        \"optimal_discount\": float,\n",
        "        \"expected_revenue\": float,\n",
        "        \"final_selling_price\": float,\n",
        "        \"confidence\": str\n",
        "    }\n",
        "    \"\"\"\n",
        "    # Default to current date if not provided\n",
        "    if month is None:\n",
        "        month = datetime.now().month\n",
        "    if day_of_week is None:\n",
        "        day_of_week = datetime.now().weekday()\n",
        "    if is_weekend is None:\n",
        "        is_weekend = 1 if datetime.now().weekday() >= 5 else 0\n",
        "    \n",
        "    # Encode category\n",
        "    try:\n",
        "        category_encoded = category_encoder.transform([category])[0]\n",
        "    except ValueError:\n",
        "        # If category not seen, use most common category\n",
        "        category_encoded = category_encoder.transform([category_encoder.classes_[0]])[0]\n",
        "    \n",
        "    # Calculate sales volume percentile\n",
        "    sales_volume_percentile = 0  # Default\n",
        "    \n",
        "    # Learn elasticity patterns from training data if available\n",
        "    if training_df is not None:\n",
        "        # Calculate average elasticity by category from training data\n",
        "        category_elasticity = training_df.groupby('category')['price_elasticity_estimate'].mean()\n",
        "        base_elasticity = category_elasticity.get(category, -1.5)\n",
        "        \n",
        "        # Calculate average quantity at 0% discount for this category\n",
        "        base_quantity = training_df[\n",
        "            (training_df['category'] == category) & \n",
        "            (training_df['offered_discount'] < 1)\n",
        "        ]['quantity_ordered'].mean()\n",
        "        if pd.isna(base_quantity) or base_quantity == 0:\n",
        "            base_quantity = training_df[training_df['category'] == category]['quantity_ordered'].mean()\n",
        "        if pd.isna(base_quantity) or base_quantity == 0:\n",
        "            base_quantity = 5.0  # Default fallback\n",
        "    else:\n",
        "        base_elasticity = -1.5\n",
        "        base_quantity = 5.0\n",
        "    \n",
        "    # Simulate different discount percentages (0-30%)\n",
        "    discount_range = np.arange(0, 31, 0.5)  # 0 to 30% in 0.5% increments\n",
        "    revenue_predictions = []\n",
        "    \n",
        "    for discount_pct in discount_range:\n",
        "        # Calculate discounted price\n",
        "        discounted_price = base_price * (1 - discount_pct / 100)\n",
        "        \n",
        "        # Estimate how discount affects quantity (price elasticity)\n",
        "        # Higher discount = higher quantity, but with diminishing returns\n",
        "        price_change_pct = discount_pct / 100\n",
        "        \n",
        "        # Price elasticity: % change in quantity / % change in price\n",
        "        # If elasticity = -2, a 1% price drop leads to 2% quantity increase\n",
        "        # Convert elasticity to positive for calculation (elasticity is negative)\n",
        "        elasticity_magnitude = abs(base_elasticity)\n",
        "        \n",
        "        # Quantity increase from price elasticity\n",
        "        # For every 1% price drop, quantity increases by elasticity_magnitude%\n",
        "        quantity_elasticity_boost = 1 + (elasticity_magnitude * price_change_pct)\n",
        "        \n",
        "        # Additional conversion boost (higher discount = more likely to purchase)\n",
        "        # Higher discounts increase conversion probability\n",
        "        conversion_boost = 1 + (price_change_pct * 0.5)  # 10% discount = 5% conversion boost\n",
        "        \n",
        "        # Estimate expected quantity with discount\n",
        "        expected_quantity = base_quantity * quantity_elasticity_boost * conversion_boost\n",
        "        \n",
        "        # Estimate price elasticity for the feature vector (for model input)\n",
        "        # Elasticity becomes more negative (more elastic) with higher discounts\n",
        "        elasticity = base_elasticity * (1 + price_change_pct * 0.2)\n",
        "        \n",
        "        # Prepare feature vector\n",
        "        features = np.array([[\n",
        "            base_price,\n",
        "            discount_pct,\n",
        "            category_encoded,\n",
        "            past_sales_volume,\n",
        "            elasticity,\n",
        "            month,\n",
        "            day_of_week,\n",
        "            is_weekend,\n",
        "            sales_volume_percentile\n",
        "        ]])\n",
        "        \n",
        "        # Scale features\n",
        "        features_scaled = scaler.transform(features)\n",
        "        \n",
        "        # Predict revenue from model (model was trained on actual revenue = price Ã— quantity)\n",
        "        predicted_revenue_model = model.predict(features_scaled)[0]\n",
        "        \n",
        "        # Calculate revenue directly from expected quantity and discounted price\n",
        "        # This properly accounts for elasticity: Revenue = Price Ã— Quantity\n",
        "        # Where Quantity increases with discount based on elasticity\n",
        "        expected_revenue_direct = discounted_price * expected_quantity\n",
        "        \n",
        "        # The model learned from historical data, but might be conservative\n",
        "        # Use the direct calculation which properly models elasticity\n",
        "        # But blend with model prediction for robustness\n",
        "        final_expected_revenue = 0.7 * expected_revenue_direct + 0.3 * predicted_revenue_model\n",
        "        \n",
        "        # Only consider positive revenue\n",
        "        if final_expected_revenue > 0:\n",
        "            revenue_predictions.append({\n",
        "                'discount': discount_pct,\n",
        "                'revenue': final_expected_revenue,\n",
        "                'discounted_price': discounted_price,\n",
        "                'expected_quantity': expected_quantity\n",
        "            })\n",
        "    \n",
        "    if not revenue_predictions:\n",
        "        # Fallback: return 0% discount\n",
        "        optimal_discount = 0.0\n",
        "        expected_revenue = base_price * base_quantity\n",
        "        discounted_price = base_price\n",
        "        confidence = \"Low\"\n",
        "    else:\n",
        "        # Find discount that maximizes revenue\n",
        "        revenue_df = pd.DataFrame(revenue_predictions)\n",
        "        optimal_idx = revenue_df['revenue'].idxmax()\n",
        "        optimal_discount = revenue_df.loc[optimal_idx, 'discount']\n",
        "        expected_revenue = revenue_df.loc[optimal_idx, 'revenue']\n",
        "        discounted_price = revenue_df.loc[optimal_idx, 'discounted_price']\n",
        "        \n",
        "        # Calculate confidence based on revenue difference\n",
        "        max_revenue = revenue_df['revenue'].max()\n",
        "        second_max_revenue = revenue_df.nlargest(2, 'revenue')['revenue'].iloc[-1] if len(revenue_df) > 1 else max_revenue\n",
        "        revenue_diff_pct = ((max_revenue - second_max_revenue) / (second_max_revenue + 1e-6)) * 100\n",
        "        \n",
        "        if revenue_diff_pct > 10:\n",
        "            confidence = \"High\"\n",
        "        elif revenue_diff_pct > 5:\n",
        "            confidence = \"Medium\"\n",
        "        else:\n",
        "            confidence = \"Low\"\n",
        "    \n",
        "    # Get product name (simplified - in practice, query from database)\n",
        "    product_name = f\"Product {product_id}\"\n",
        "    \n",
        "    return {\n",
        "        \"product\": product_name,\n",
        "        \"optimal_discount\": round(optimal_discount, 2),\n",
        "        \"expected_revenue\": round(expected_revenue, 2),\n",
        "        \"final_selling_price\": round(discounted_price, 2),\n",
        "        \"confidence\": confidence\n",
        "    }\n",
        "\n",
        "print(\"âœ… Optimal discount prediction function created (improved with elasticity patterns)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.5. Test Discount Calculation Logic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§ª Testing discount calculation logic...\n",
            "\n",
            "Test parameters:\n",
            "  Base Price: â‚¹100.0\n",
            "  Base Quantity: 5.0 units\n",
            "  Elasticity: -2.0 (elastic product)\n",
            "\n",
            "   0% discount: Price=â‚¹100.00, Qty= 5.00, Revenue=â‚¹ 500.00 (+0.0%)\n",
            "   5% discount: Price=â‚¹ 95.00, Qty= 5.64, Revenue=â‚¹ 535.56 (+7.1%)\n",
            "  10% discount: Price=â‚¹ 90.00, Qty= 6.30, Revenue=â‚¹ 567.00 (+13.4%)\n",
            "  15% discount: Price=â‚¹ 85.00, Qty= 6.99, Revenue=â‚¹ 593.94 (+18.8%)\n",
            "  20% discount: Price=â‚¹ 80.00, Qty= 7.70, Revenue=â‚¹ 616.00 (+23.2%)\n",
            "  25% discount: Price=â‚¹ 75.00, Qty= 8.44, Revenue=â‚¹ 632.81 (+26.6%)\n",
            "  30% discount: Price=â‚¹ 70.00, Qty= 9.20, Revenue=â‚¹ 644.00 (+28.8%)\n",
            "\n",
            "âœ… Discount calculation test completed\n",
            "   Note: With elasticity > 1, discounts should increase revenue!\n"
          ]
        }
      ],
      "source": [
        "# Quick test to verify discount calculation logic\n",
        "print(\"ğŸ§ª Testing discount calculation logic...\\n\")\n",
        "\n",
        "# Test with a sample product\n",
        "test_base_price = 100.0\n",
        "test_base_quantity = 5.0\n",
        "test_elasticity = -2.0  # Elastic price: 1% price drop â†’ 2% quantity increase\n",
        "\n",
        "print(f\"Test parameters:\")\n",
        "print(f\"  Base Price: â‚¹{test_base_price}\")\n",
        "print(f\"  Base Quantity: {test_base_quantity} units\")\n",
        "print(f\"  Elasticity: {test_elasticity} (elastic product)\\n\")\n",
        "\n",
        "for discount in [0, 5, 10, 15, 20, 25, 30]:\n",
        "    price_change = discount / 100\n",
        "    discounted_price = test_base_price * (1 - price_change)\n",
        "    \n",
        "    # Quantity increase from elasticity\n",
        "    quantity_boost = 1 + (abs(test_elasticity) * price_change)\n",
        "    conversion_boost = 1 + (price_change * 0.5)\n",
        "    expected_quantity = test_base_quantity * quantity_boost * conversion_boost\n",
        "    \n",
        "    revenue = discounted_price * expected_quantity\n",
        "    revenue_change_pct = ((revenue - (test_base_price * test_base_quantity)) / (test_base_price * test_base_quantity)) * 100\n",
        "    \n",
        "    print(f\"  {discount:2d}% discount: Price=â‚¹{discounted_price:6.2f}, Qty={expected_quantity:5.2f}, Revenue=â‚¹{revenue:7.2f} ({revenue_change_pct:+.1f}%)\")\n",
        "\n",
        "print(\"\\nâœ… Discount calculation test completed\")\n",
        "print(\"   Note: With elasticity > 1, discounts should increase revenue!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Model results preserved for validation summary\n"
          ]
        }
      ],
      "source": [
        "# Preserve model training results before demo\n",
        "model_results = results.copy()  # Save model results dictionary\n",
        "print(\"âœ… Model results preserved for validation summary\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Model artifacts saved:\n",
            "   Model: ../ml_models\\dynamic_pricing_model.pkl\n",
            "   Scaler: ../ml_models\\input_scaler.pkl\n",
            "   Encoder: ../ml_models\\product_encoder.pkl\n",
            "\n",
            "ğŸ“‹ Model info:\n",
            "   Model type: RandomForest\n",
            "   Features: 9\n",
            "   Feature names: ['base_price', 'offered_discount', 'category_encoded', 'past_sales_volume', 'price_elasticity_estimate', 'month', 'day_of_week', 'is_weekend', 'sales_volume_percentile']\n"
          ]
        }
      ],
      "source": [
        "# Create models directory if it doesn't exist\n",
        "models_dir = '../ml_models'\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "# Save model artifacts\n",
        "model_path = os.path.join(models_dir, 'dynamic_pricing_model.pkl')\n",
        "scaler_path = os.path.join(models_dir, 'input_scaler.pkl')\n",
        "encoder_path = os.path.join(models_dir, 'product_encoder.pkl')\n",
        "\n",
        "joblib.dump(selected_model, model_path)\n",
        "joblib.dump(scaler, scaler_path)\n",
        "joblib.dump(category_encoder, encoder_path)\n",
        "\n",
        "print(\"âœ… Model artifacts saved:\")\n",
        "print(f\"   Model: {model_path}\")\n",
        "print(f\"   Scaler: {scaler_path}\")\n",
        "print(f\"   Encoder: {encoder_path}\")\n",
        "print(f\"\\nğŸ“‹ Model info:\")\n",
        "print(f\"   Model type: {selected_model_name}\")\n",
        "print(f\"   Features: {len(feature_columns_encoded)}\")\n",
        "print(f\"   Feature names: {feature_columns_encoded}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Demo: Test Optimal Discount Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ Demo: Optimal Discount Predictions for Sample Products\n",
            "\n",
            "================================================================================\n",
            "\n",
            "ğŸ“¦ Organic Tomatoes\n",
            "   Base Price: â‚¹80.00\n",
            "   Category: Vegetables\n",
            "   Past Sales Volume: 150\n",
            "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "   ğŸ’¡ Optimal Discount: 30.5%\n",
            "   ğŸ’° Final Selling Price: â‚¹55.60\n",
            "   ğŸ“ˆ Expected Revenue: â‚¹873.87\n",
            "   ğŸ¯ Confidence: Low\n",
            "\n",
            "ğŸ“¦ Fresh Mangoes\n",
            "   Base Price: â‚¹120.00\n",
            "   Category: Fruits\n",
            "   Past Sales Volume: 200\n",
            "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "   ğŸ’¡ Optimal Discount: 30.5%\n",
            "   ğŸ’° Final Selling Price: â‚¹83.40\n",
            "   ğŸ“ˆ Expected Revenue: â‚¹1447.79\n",
            "   ğŸ¯ Confidence: Low\n",
            "\n",
            "ğŸ“¦ Toor Dal\n",
            "   Base Price: â‚¹120.00\n",
            "   Category: Grains\n",
            "   Past Sales Volume: 300\n",
            "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "   ğŸ’¡ Optimal Discount: 24.5%\n",
            "   ğŸ’° Final Selling Price: â‚¹90.60\n",
            "   ğŸ“ˆ Expected Revenue: â‚¹1443.54\n",
            "   ğŸ¯ Confidence: Low\n",
            "\n",
            "ğŸ“¦ Turmeric Powder\n",
            "   Base Price: â‚¹250.00\n",
            "   Category: Spices\n",
            "   Past Sales Volume: 100\n",
            "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "   ğŸ’¡ Optimal Discount: 30.5%\n",
            "   ğŸ’° Final Selling Price: â‚¹173.75\n",
            "   ğŸ“ˆ Expected Revenue: â‚¹2818.76\n",
            "   ğŸ¯ Confidence: Low\n",
            "\n",
            "ğŸ“¦ Fresh Milk\n",
            "   Base Price: â‚¹60.00\n",
            "   Category: Dairy\n",
            "   Past Sales Volume: 500\n",
            "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "   ğŸ’¡ Optimal Discount: 30.5%\n",
            "   ğŸ’° Final Selling Price: â‚¹41.70\n",
            "   ğŸ“ˆ Expected Revenue: â‚¹729.24\n",
            "   ğŸ¯ Confidence: Low\n",
            "\n",
            "================================================================================\n",
            "\n",
            "âœ… Demo completed successfully!\n"
          ]
        }
      ],
      "source": [
        "print(\"ğŸ¯ Demo: Optimal Discount Predictions for Sample Products\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Test with 5 different products\n",
        "demo_products = [\n",
        "    {\n",
        "        'product_id': 'PROD_Vegetables_1',\n",
        "        'product_name': 'Organic Tomatoes',\n",
        "        'base_price': 80.0,\n",
        "        'category': 'Vegetables',\n",
        "        'past_sales_volume': 150\n",
        "    },\n",
        "    {\n",
        "        'product_id': 'PROD_Fruits_1',\n",
        "        'product_name': 'Fresh Mangoes',\n",
        "        'base_price': 120.0,\n",
        "        'category': 'Fruits',\n",
        "        'past_sales_volume': 200\n",
        "    },\n",
        "    {\n",
        "        'product_id': 'PROD_Grains_1',\n",
        "        'product_name': 'Toor Dal',\n",
        "        'base_price': 120.0,\n",
        "        'category': 'Grains',\n",
        "        'past_sales_volume': 300\n",
        "    },\n",
        "    {\n",
        "        'product_id': 'PROD_Spices_1',\n",
        "        'product_name': 'Turmeric Powder',\n",
        "        'base_price': 250.0,\n",
        "        'category': 'Spices',\n",
        "        'past_sales_volume': 100\n",
        "    },\n",
        "    {\n",
        "        'product_id': 'PROD_Dairy_1',\n",
        "        'product_name': 'Fresh Milk',\n",
        "        'base_price': 60.0,\n",
        "        'category': 'Dairy',\n",
        "        'past_sales_volume': 500\n",
        "    }\n",
        "]\n",
        "\n",
        "results = []\n",
        "for product in demo_products:\n",
        "    result = predict_optimal_discount(\n",
        "        product_id=product['product_id'],\n",
        "        base_price=product['base_price'],\n",
        "        category=product['category'],\n",
        "        past_sales_volume=product['past_sales_volume'],\n",
        "        model=selected_model,\n",
        "        scaler=scaler,\n",
        "        category_encoder=category_encoder,\n",
        "        training_df=df_train  # Pass training data to learn elasticity patterns\n",
        "    )\n",
        "    \n",
        "    # Update with actual product name\n",
        "    result['product'] = product['product_name']\n",
        "    \n",
        "    results.append({\n",
        "        **product,\n",
        "        **result\n",
        "    })\n",
        "    \n",
        "    print(f\"\\nğŸ“¦ {product['product_name']}\")\n",
        "    print(f\"   Base Price: â‚¹{product['base_price']:.2f}\")\n",
        "    print(f\"   Category: {product['category']}\")\n",
        "    print(f\"   Past Sales Volume: {product['past_sales_volume']}\")\n",
        "    print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "    print(f\"   ğŸ’¡ Optimal Discount: {result['optimal_discount']:.1f}%\")\n",
        "    print(f\"   ğŸ’° Final Selling Price: â‚¹{result['final_selling_price']:.2f}\")\n",
        "    print(f\"   ğŸ“ˆ Expected Revenue: â‚¹{result['expected_revenue']:.2f}\")\n",
        "    print(f\"   ğŸ¯ Confidence: {result['confidence']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"\\nâœ… Demo completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Error Handling: Unseen Products\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Model results restored for validation summary\n"
          ]
        }
      ],
      "source": [
        "# Fix: Restore model results if they were overwritten by demo\n",
        "if 'model_results' in globals():\n",
        "    results = model_results.copy()\n",
        "    print(\"âœ… Model results restored for validation summary\")\n",
        "else:\n",
        "    print(\"âš ï¸  Note: Run cell 21 before the demo to preserve model results\")\n",
        "    print(\"   If you see this error, re-run cells 14-16 (model training) first\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§ª Testing error handling for unseen products...\n",
            "\n",
            "âœ… Unseen category handled gracefully\n",
            "   Result: {'product': 'Product PROD_UNSEEN_1', 'optimal_discount': np.float64(0.0), 'expected_revenue': np.float64(559.34), 'final_selling_price': np.float64(100.0), 'confidence': 'Low'}\n",
            "\n",
            "ğŸ“Š Category average discount analysis:\n",
            "category\n",
            "Dairy         15.010808\n",
            "Fruits        14.732735\n",
            "Grains        14.392474\n",
            "Nuts          14.614661\n",
            "Oil           14.990120\n",
            "Pulses        15.014667\n",
            "Spices        15.416559\n",
            "Vegetables    14.503005\n",
            "Name: offered_discount, dtype: float64\n",
            "\n",
            "âœ… Error handling verified!\n"
          ]
        }
      ],
      "source": [
        "# Test with unseen category\n",
        "print(\"ğŸ§ª Testing error handling for unseen products...\\n\")\n",
        "\n",
        "# Test with unseen category\n",
        "try:\n",
        "    result = predict_optimal_discount(\n",
        "        product_id='PROD_UNSEEN_1',\n",
        "        base_price=100.0,\n",
        "        category='UnseenCategory',  # Category not in training data\n",
        "        past_sales_volume=50,\n",
        "        model=selected_model,\n",
        "        scaler=scaler,\n",
        "        category_encoder=category_encoder,\n",
        "        training_df=df_train\n",
        "    )\n",
        "    print(\"âœ… Unseen category handled gracefully\")\n",
        "    print(f\"   Result: {result}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error with unseen category: {e}\")\n",
        "\n",
        "# Test with category average (fallback)\n",
        "print(\"\\nğŸ“Š Category average discount analysis:\")\n",
        "category_avg_discounts = df_train.groupby('category')['offered_discount'].mean()\n",
        "print(category_avg_discounts)\n",
        "\n",
        "print(\"\\nâœ… Error handling verified!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Model Validation Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Model Validation Summary\n",
            "================================================================================\n",
            "\n",
            "ğŸ† Selected Model: RandomForest\n",
            "   RÂ² Score: 0.8570\n",
            "   RMSE: 777.4238\n",
            "   MAE: 486.7777\n",
            "\n",
            "ğŸ“‹ Training Data:\n",
            "   Total samples: 3138\n",
            "   Training set: 2510\n",
            "   Test set: 628\n",
            "\n",
            "ğŸ”§ Features Used (9):\n",
            "   1. base_price\n",
            "   2. offered_discount\n",
            "   3. category_encoded\n",
            "   4. past_sales_volume\n",
            "   5. price_elasticity_estimate\n",
            "   6. month\n",
            "   7. day_of_week\n",
            "   8. is_weekend\n",
            "   9. sales_volume_percentile\n",
            "\n",
            "ğŸ’¾ Saved Artifacts:\n",
            "   âœ“ dynamic_pricing_model.pkl\n",
            "   âœ“ input_scaler.pkl\n",
            "   âœ“ product_encoder.pkl\n",
            "\n",
            "âœ… Model is ready for deployment!\n",
            "   Use predict_optimal_discount() function to get recommendations\n"
          ]
        }
      ],
      "source": [
        "print(\"ğŸ“Š Model Validation Summary\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nğŸ† Selected Model: {selected_model_name}\")\n",
        "print(f\"   RÂ² Score: {results[selected_model_name]['r2']:.4f}\")\n",
        "print(f\"   RMSE: {results[selected_model_name]['rmse']:.4f}\")\n",
        "print(f\"   MAE: {results[selected_model_name]['mae']:.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ“‹ Training Data:\")\n",
        "print(f\"   Total samples: {len(df_train)}\")\n",
        "print(f\"   Training set: {len(X_train)}\")\n",
        "print(f\"   Test set: {len(X_test)}\")\n",
        "\n",
        "print(f\"\\nğŸ”§ Features Used ({len(feature_columns_encoded)}):\")\n",
        "for i, feat in enumerate(feature_columns_encoded, 1):\n",
        "    print(f\"   {i}. {feat}\")\n",
        "\n",
        "print(f\"\\nğŸ’¾ Saved Artifacts:\")\n",
        "print(f\"   âœ“ dynamic_pricing_model.pkl\")\n",
        "print(f\"   âœ“ input_scaler.pkl\")\n",
        "print(f\"   âœ“ product_encoder.pkl\")\n",
        "\n",
        "print(f\"\\nâœ… Model is ready for deployment!\")\n",
        "print(f\"   Use predict_optimal_discount() function to get recommendations\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
